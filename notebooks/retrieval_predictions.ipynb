{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "retrieval_predictions.ipynb",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bf-86KknHHps"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/google-research/tapas/blob/master/notebooks/retrieval_predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8XF59AeJask"
      },
      "source": [
        "##### Copyright 2020 The Google AI Language Team Authors\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnPwClY0taWp"
      },
      "source": [
        "# Copyright 2021 The Google AI Language Team Authors.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jiJ5VvrJkih"
      },
      "source": [
        "# Run TAPAS retrieval models description\n",
        "This notebook shows how to use retrieval models, which was introduced in the paper: [Open Domain Question Answering over Tables via Dense Retrieval](https://arxiv.org/pdf/2103.12011.pdf).\n",
        "1.   Load pre-trained and fine-tuned models.\n",
        "      > * the dual encoder. (called tapas_retriever)\n",
        "      > * the reader models. (called tapas_reader)\n",
        "2.   Add handcrafted query and extract the interactions and tf-examples.\n",
        "3.   Get nearest neighbors for each query, and extract the interactions to pass to the reader.\n",
        "4.   Call the reader on the new interactions and print\n",
        "      > * the query.\n",
        "      > * the probability of this table containing the answer.\n",
        "      > * the table with a highlighted answer found by the reader.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9Z8tP11vCOl",
        "outputId": "61232829-6e83-4104-da50-c1d024ba2637",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Clone and install the repository\n",
        "! sudo apt-get install protobuf-compiler\n",
        "! git clone https://github.com/google-research/tapas\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "protobuf-compiler is already the newest version (3.12.4-1ubuntu7.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Cloning into 'tapas'...\n",
            "remote: Enumerating objects: 822, done.\u001b[K\n",
            "remote: Counting objects: 100% (240/240), done.\u001b[K\n",
            "remote: Compressing objects: 100% (139/139), done.\u001b[K\n",
            "remote: Total 822 (delta 119), reused 188 (delta 101), pack-reused 582\u001b[K\n",
            "Receiving objects: 100% (822/822), 861.24 KiB | 2.75 MiB/s, done.\n",
            "Resolving deltas: 100% (472/472), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "! pip install -e ./tapas\n"
      ],
      "metadata": {
        "id": "WGnyHqlDxHxV",
        "outputId": "51e1e592-a0a3-4a21-925a-103f492a2b4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/tapas\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: apache-beam[gcp]>=2.28.0 in /usr/local/lib/python3.10/dist-packages (from tapas-table-parsing==0.0.1.dev0) (2.54.0)\n",
            "Requirement already satisfied: frozendict>=2.3 in /usr/local/lib/python3.10/dist-packages (from tapas-table-parsing==0.0.1.dev0) (2.4.0)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tapas-table-parsing==0.0.1.dev0) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.10/dist-packages (from tapas-table-parsing==0.0.1.dev0) (1.2.2)\n",
            "Requirement already satisfied: tensorflow>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from tapas-table-parsing==0.0.1.dev0) (2.15.0)\n",
            "Requirement already satisfied: tf-models-official>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from tapas-table-parsing==0.0.1.dev0) (2.15.0)\n",
            "Requirement already satisfied: kaggle~=1.5.8 in /usr/local/lib/python3.10/dist-packages (from tapas-table-parsing==0.0.1.dev0) (1.5.16)\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.10/dist-packages (from tapas-table-parsing==0.0.1.dev0) (0.23.0)\n",
            "Requirement already satisfied: tf_slim~=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tapas-table-parsing==0.0.1.dev0) (1.1.0)\n",
            "Requirement already satisfied: nltk~=3.5 in /usr/local/lib/python3.10/dist-packages (from tapas-table-parsing==0.0.1.dev0) (3.8.1)\n",
            "Collecting beautifulsoup4>=4.11 (from tapas-table-parsing==0.0.1.dev0)\n",
            "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.9/147.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: html5lib==1.1 in /usr/local/lib/python3.10/dist-packages (from tapas-table-parsing==0.0.1.dev0) (1.1)\n",
            "Requirement already satisfied: gensim>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from tapas-table-parsing==0.0.1.dev0) (4.3.2)\n",
            "Collecting lxml>=4.9 (from tapas-table-parsing==0.0.1.dev0)\n",
            "  Downloading lxml-5.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dataclasses in /usr/local/lib/python3.10/dist-packages (from tapas-table-parsing==0.0.1.dev0) (0.6)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib==1.1->tapas-table-parsing==0.0.1.dev0) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib==1.1->tapas-table-parsing==0.0.1.dev0) (0.5.1)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (1.7)\n",
            "Requirement already satisfied: orjson<4,>=3.9.7 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (3.9.15)\n",
            "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (0.3.1.1)\n",
            "Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (2.2.1)\n",
            "Requirement already satisfied: fastavro<2,>=0.23.6 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (1.9.4)\n",
            "Requirement already satisfied: fasteners<1.0,>=0.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (0.19)\n",
            "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (1.62.0)\n",
            "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (2.7.3)\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (0.22.0)\n",
            "Requirement already satisfied: js2py<1,>=0.74 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (0.74)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (4.19.2)\n",
            "Requirement already satisfied: jsonpickle<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (3.0.3)\n",
            "Requirement already satisfied: numpy<1.25.0,>=1.14.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (1.24.4)\n",
            "Requirement already satisfied: objsize<0.8.0,>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (0.7.0)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (23.2)\n",
            "Requirement already satisfied: pymongo<5.0.0,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (4.6.2)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (1.23.0)\n",
            "Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<4.26.0,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (3.20.3)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (2023.4)\n",
            "Requirement already satisfied: regex>=2020.6.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (2023.12.25)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (4.10.0)\n",
            "Requirement already satisfied: zstandard<1,>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (0.22.0)\n",
            "Requirement already satisfied: pyarrow<15.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix<1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (0.6)\n",
            "Requirement already satisfied: cachetools<6,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (5.3.3)\n",
            "Requirement already satisfied: google-api-core<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (2.17.1)\n",
            "Requirement already satisfied: google-apitools<0.5.32,>=0.5.31 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (0.5.31)\n",
            "Requirement already satisfied: google-auth<3,>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (0.1.1)\n",
            "Requirement already satisfied: google-cloud-datastore<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (2.15.2)\n",
            "Requirement already satisfied: google-cloud-pubsub<3,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (2.19.7)\n",
            "Requirement already satisfied: google-cloud-pubsublite<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (1.9.0)\n",
            "Requirement already satisfied: google-cloud-storage<3,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (2.14.0)\n",
            "Requirement already satisfied: google-cloud-bigquery<4,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (3.12.0)\n",
            "Requirement already satisfied: google-cloud-bigquery-storage<3,>=2.6.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (2.24.0)\n",
            "Requirement already satisfied: google-cloud-core<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (2.3.3)\n",
            "Requirement already satisfied: google-cloud-bigtable<3,>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (2.23.0)\n",
            "Requirement already satisfied: google-cloud-spanner<4,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (3.42.0)\n",
            "Requirement already satisfied: google-cloud-dlp<4,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (3.15.2)\n",
            "Requirement already satisfied: google-cloud-language<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (2.13.2)\n",
            "Requirement already satisfied: google-cloud-videointelligence<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (2.13.2)\n",
            "Requirement already satisfied: google-cloud-vision<4,>=2 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (3.7.1)\n",
            "Requirement already satisfied: google-cloud-recommendations-ai<0.11.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (0.10.9)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2.0,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (1.42.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11->tapas-table-parsing==0.0.1.dev0) (2.5)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim>=3.8.3->tapas-table-parsing==0.0.1.dev0) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim>=3.8.3->tapas-table-parsing==0.0.1.dev0) (6.4.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle~=1.5.8->tapas-table-parsing==0.0.1.dev0) (2024.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle~=1.5.8->tapas-table-parsing==0.0.1.dev0) (4.66.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle~=1.5.8->tapas-table-parsing==0.0.1.dev0) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle~=1.5.8->tapas-table-parsing==0.0.1.dev0) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle~=1.5.8->tapas-table-parsing==0.0.1.dev0) (6.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk~=3.5->tapas-table-parsing==0.0.1.dev0) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk~=3.5->tapas-table-parsing==0.0.1.dev0) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.1->tapas-table-parsing==0.0.1.dev0) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->tapas-table-parsing==0.0.1.dev0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->tapas-table-parsing==0.0.1.dev0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->tapas-table-parsing==0.0.1.dev0) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->tapas-table-parsing==0.0.1.dev0) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->tapas-table-parsing==0.0.1.dev0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->tapas-table-parsing==0.0.1.dev0) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->tapas-table-parsing==0.0.1.dev0) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->tapas-table-parsing==0.0.1.dev0) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->tapas-table-parsing==0.0.1.dev0) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->tapas-table-parsing==0.0.1.dev0) (67.7.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->tapas-table-parsing==0.0.1.dev0) (2.4.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->tapas-table-parsing==0.0.1.dev0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->tapas-table-parsing==0.0.1.dev0) (0.36.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->tapas-table-parsing==0.0.1.dev0) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->tapas-table-parsing==0.0.1.dev0) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->tapas-table-parsing==0.0.1.dev0) (2.15.0)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.2.0->tapas-table-parsing==0.0.1.dev0) (3.0.8)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.2.0->tapas-table-parsing==0.0.1.dev0) (9.4.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.2.0->tapas-table-parsing==0.0.1.dev0) (0.5.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.2.0->tapas-table-parsing==0.0.1.dev0) (2.84.0)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.2.0->tapas-table-parsing==0.0.1.dev0) (4.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.2.0->tapas-table-parsing==0.0.1.dev0) (3.7.1)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.2.0->tapas-table-parsing==0.0.1.dev0) (4.1.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.2.0->tapas-table-parsing==0.0.1.dev0) (4.9.0.80)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.2.0->tapas-table-parsing==0.0.1.dev0) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.2.0->tapas-table-parsing==0.0.1.dev0) (9.0.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.2.0->tapas-table-parsing==0.0.1.dev0) (2.0.7)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.2.0->tapas-table-parsing==0.0.1.dev0) (6.0.1)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.2.0->tapas-table-parsing==0.0.1.dev0) (2.4.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.2.0->tapas-table-parsing==0.0.1.dev0) (0.1.99)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.2.0->tapas-table-parsing==0.0.1.dev0) (1.2.2)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.2.0->tapas-table-parsing==0.0.1.dev0) (4.9.4)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.2.0->tapas-table-parsing==0.0.1.dev0) (0.16.1)\n",
            "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.2.0->tapas-table-parsing==0.0.1.dev0) (0.8.0)\n",
            "Requirement already satisfied: tensorflow-text~=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.2.0->tapas-table-parsing==0.0.1.dev0) (2.15.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability->tapas-table-parsing==0.0.1.dev0) (4.4.2)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability->tapas-table-parsing==0.0.1.dev0) (0.1.8)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.2.0->tapas-table-parsing==0.0.1.dev0) (0.42.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3,>=2.0.0->apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (1.62.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.2.0->tapas-table-parsing==0.0.1.dev0) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (4.9)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (1.12.2)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (2.0.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4,>=2.0.0->apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (2.7.0)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigtable<3,>=2.19.0->apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (0.13.0)\n",
            "Requirement already satisfied: grpcio-status>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (1.48.2)\n",
            "Requirement already satisfied: overrides<8.0.0,>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsublite<2,>=1.2.0->apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (7.7.0)\n",
            "Requirement already satisfied: sqlparse>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-spanner<4,>=3.0.0->apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (0.4.4)\n",
            "Requirement already satisfied: deprecated>=1.2.14 in /usr/local/lib/python3.10/dist-packages (from google-cloud-spanner<4,>=3.0.0->apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (1.2.14)\n",
            "Requirement already satisfied: grpc-interceptor>=0.15.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-spanner<4,>=3.0.0->apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (0.15.4)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3,>=2.14.0->apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (1.5.0)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.10/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (0.6.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<0.23.0,>=0.8->apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (3.1.1)\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.10/dist-packages (from js2py<1,>=0.74->apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (5.2)\n",
            "Requirement already satisfied: pyjsparser>=2.5.1 in /usr/local/lib/python3.10/dist-packages (from js2py<1,>=0.74->apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (2.7.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (0.18.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.2.0->tapas-table-parsing==0.0.1.dev0) (0.5.1)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo<5.0.0,>=3.8.0->apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (2.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]>=2.28.0->tapas-table-parsing==0.0.1.dev0) (3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.2.0->tapas-table-parsing==0.0.1.dev0) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.2.0->tapas-table-parsing==0.0.1.dev0) (3.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.2.0->tapas-table-parsing==0.0.1.dev0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.2.0->tapas-table-parsing==0.0.1.dev0) (3.0.1)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub>=0.6.0->tf-models-official>=2.2.0->tapas-table-parsing==0.0.1.dev0) (2.15.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official>=2.2.0->tapas-table-parsing==0.0.1.dev0) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official>=2.2.0->tapas-table-parsing==0.0.1.dev0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official>=2.2.0->tapas-table-parsing==0.0.1.dev0) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official>=2.2.0->tapas-table-parsing==0.0.1.dev0) (1.4.5)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle~=1.5.8->tapas-table-parsing==0.0.1.dev0) (1.3)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official>=2.2.0->tapas-table-parsing==0.0.1.dev0) (2.8.2)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official>=2.2.0->tapas-table-parsing==0.0.1.dev0) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official>=2.2.0->tapas-table-parsing==0.0.1.dev0) (0.4.6)\n",
            "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.2.0->tapas-table-parsing==0.0.1.dev0) (1.7.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.2.0->tapas-table-parsing==0.0.1.dev0) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.2.0->tapas-table-parsing==0.0.1.dev0) (1.14.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.2.0->tapas-table-parsing==0.0.1.dev0) (0.10.2)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.2.0->tapas-table-parsing==0.0.1.dev0) (0.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official>=2.2.0->tapas-table-parsing==0.0.1.dev0) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official>=2.2.0->tapas-table-parsing==0.0.1.dev0) (6.1.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official>=2.2.0->tapas-table-parsing==0.0.1.dev0) (3.17.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.2.0->tapas-table-parsing==0.0.1.dev0) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow>=2.2.0->tapas-table-parsing==0.0.1.dev0) (2.1.5)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.2.0->tapas-table-parsing==0.0.1.dev0) (3.2.2)\n",
            "Installing collected packages: lxml, beautifulsoup4, tapas-table-parsing\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.6.5\n",
            "    Uninstalling lxml-4.6.5:\n",
            "      Successfully uninstalled lxml-4.6.5\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.9.3\n",
            "    Uninstalling beautifulsoup4-4.9.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.9.3\n",
            "  Attempting uninstall: tapas-table-parsing\n",
            "    Found existing installation: tapas-table-parsing 0.0.1.dev0\n",
            "    Uninstalling tapas-table-parsing-0.0.1.dev0:\n",
            "      Successfully uninstalled tapas-table-parsing-0.0.1.dev0\n",
            "  Running setup.py develop for tapas-table-parsing\n",
            "Successfully installed beautifulsoup4-4.12.3 lxml-5.1.0 tapas-table-parsing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Run the imports needed for all the colab\n",
        "import tensorflow.compat.v1 as tf\n",
        "import os\n",
        "import shutil\n",
        "import csv\n",
        "import pandas as pd\n",
        "import IPython\n",
        "import ast\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "from tapas.utils import tf_example_utils\n",
        "from tapas.utils import beam_runner\n",
        "from tapas.utils import create_data\n",
        "from tapas.protos import interaction_pb2\n",
        "from tapas.utils import number_annotation_utils\n",
        "from tapas.scripts import prediction_utils\n",
        "from tapas.scripts import eval_table_retriever_utils\n",
        "from tapas.retrieval import tf_example_utils as retrieval_utils\n",
        "from tapas.experiments import table_retriever_experiment\n"
      ],
      "metadata": {
        "id": "XSVEMw4ixETN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fiPv3GV7yXZ",
        "outputId": "2dcc02a8-6386-46d2-fa24-e1b2f1f72837",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 1.   Load pre-trained and fine-tuned models fom Google Storage.\n",
        "# The dual encoder model\n",
        "\n",
        "# The dual encoder model\n",
        "! gsutil cp \"gs://tapas_models/2021_04_27/tapas_nq_hn_retriever_medium.zip\" \"tapas_retriever.zip\" && unzip tapas_retriever.zip\n",
        "! mv tapas_nq_hn_retriever_medium/ tapas_retriever\n",
        "\n",
        "\n",
        "# The reader model\n",
        "! gsutil cp \"gs://tapas_models/2021_04_27/tapas_nq_hn_reader_large.zip\" \"tapas_reader.zip\" && unzip tapas_reader.zip\n",
        "! mv tapas_nq_hn_reader_large tapas_reader\n",
        "\n",
        "# Load the released nq_tables data.\n",
        "os.makedirs('tapas_models_nq_tables', exist_ok=True)\n",
        "! gsutil -m cp -R gs://tapas_models/2021_07_22/nq_tables/* tapas_models_nq_tables/\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://tapas_models/2021_04_27/tapas_nq_hn_retriever_medium.zip...\n",
            "- [1 files][  1.1 GiB/  1.1 GiB]   35.8 MiB/s                                   \n",
            "Operation completed over 1 objects/1.1 GiB.                                      \n",
            "Archive:  tapas_retriever.zip\n",
            "   creating: tapas_nq_hn_retriever_medium/\n",
            "  inflating: tapas_nq_hn_retriever_medium/model.ckpt.data-00000-of-00001  \n",
            "  inflating: tapas_nq_hn_retriever_medium/model.ckpt.index  \n",
            "  inflating: tapas_nq_hn_retriever_medium/README.txt  \n",
            "  inflating: tapas_nq_hn_retriever_medium/vocab.txt  \n",
            "  inflating: tapas_nq_hn_retriever_medium/tables.tsv  \n",
            "  inflating: tapas_nq_hn_retriever_medium/bert_config.json  \n",
            "  inflating: tapas_nq_hn_retriever_medium/model.ckpt.meta  \n",
            "Copying gs://tapas_models/2021_04_27/tapas_nq_hn_reader_large.zip...\n",
            "\\ [1 files][  3.4 GiB/  3.4 GiB]   67.6 MiB/s                                   \n",
            "Operation completed over 1 objects/3.4 GiB.                                      \n",
            "Archive:  tapas_reader.zip\n",
            "   creating: tapas_nq_hn_reader_large/\n",
            "  inflating: tapas_nq_hn_reader_large/model.ckpt.data-00000-of-00001  \n",
            "  inflating: tapas_nq_hn_reader_large/model.ckpt.index  \n",
            "  inflating: tapas_nq_hn_reader_large/README.txt  \n",
            "  inflating: tapas_nq_hn_reader_large/vocab.txt  \n",
            "  inflating: tapas_nq_hn_reader_large/bert_config.json  \n",
            "  inflating: tapas_nq_hn_reader_large/model.ckpt.meta  \n",
            "Copying gs://tapas_models/2021_07_22/nq_tables/interactions/train.jsonl...\n",
            "Copying gs://tapas_models/2021_07_22/nq_tables/interactions/test.tfrecord...\n",
            "Copying gs://tapas_models/2021_07_22/nq_tables/interactions/dev.jsonl...\n",
            "Copying gs://tapas_models/2021_07_22/nq_tables/interactions/dev.tfrecord...\n",
            "Copying gs://tapas_models/2021_07_22/nq_tables/interactions/test.jsonl...\n",
            "Copying gs://tapas_models/2021_07_22/nq_tables/tables/tables.jsonl...\n",
            "Copying gs://tapas_models/2021_07_22/nq_tables/interactions/train.tfrecord...\n",
            "Copying gs://tapas_models/2021_07_22/nq_tables/tables/tables.tfrecord...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vGb8QmE6BsH"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mN0WRCQv7hr"
      },
      "source": [
        "# 2.   Add handcrafted tables, and queries\n",
        "# 2.1.   Create the needed directories.\n",
        "def create_directories():\n",
        "  \"\"\"Create directories.\"\"\"\n",
        "  # To be used for the dual encoder.\n",
        "  os.makedirs('results/nq_retrieval/model', exist_ok=True)\n",
        "  with open('results/nq_retrieval/model/checkpoint', 'w') as f:\n",
        "    f.write('model_checkpoint_path: \"model.ckpt-0\"')\n",
        "  for suffix in ['.data-00000-of-00001', '.index', '.meta']:\n",
        "    shutil.copyfile(f'tapas_retriever/model.ckpt{suffix}', f'results/nq_retrieval/model/model.ckpt-0{suffix}')\n",
        "  shutil.copyfile(f'tapas_retriever/tables.tsv', f'results/nq_retrieval/model/tables.tsv')\n",
        "  shutil.copyfile(f'tapas_retriever/bert_config.json', f'results/nq_retrieval/model/bert_config.json')\n",
        "  # To be used for nq_reder.\n",
        "  os.makedirs('results/nq_retrieval/tf_examples', exist_ok=True)\n",
        "  os.makedirs('results/nq_retrieval/queries', exist_ok=True)\n",
        "  # os.makedirs('results/nq_retrieval/tables', exist_ok=True)\n",
        "\n",
        "  os.makedirs('results/nq_reader/model', exist_ok=True)\n",
        "  os.makedirs('results/nq_reader/queries', exist_ok=True)\n",
        "  os.makedirs('results/nq_reader/nq_retrieval/tf_examples', exist_ok=True)\n",
        "  os.makedirs('results/nq_reader/nq_retrieval/model', exist_ok=True)\n",
        "\n",
        "  with open('results/nq_reader/model/checkpoint', 'w') as f:\n",
        "    f.write('model_checkpoint_path: \"model.ckpt-0\"')\n",
        "  for suffix in ['.data-00000-of-00001', '.index', '.meta']:\n",
        "    shutil.copyfile(f'tapas_reader/model.ckpt{suffix}', f'results/nq_reader/model/model.ckpt-0{suffix}')\n",
        "\n",
        "# 2.2.   Code to extract the data: the interactions than the tf_examples.\n",
        "# interaction_pb2.Interaction` protobuf object is the data structure we use to\n",
        "# store examples, and then to call the prediction script.\n",
        "def get_table(document_title, table_data):\n",
        "  \"\"\"Extracts the interaction for an str table.\n",
        "\n",
        "   Args:\n",
        "    table_data: str table where the columns are separated by '|'.\n",
        "    document_title: str title of the page containing the table or a table title\n",
        "      it also could be empty str.\"\"\"\n",
        "  table = [list(map(lambda s: s.strip(), row.split(\"|\")))\n",
        "           for row in table_data.split(\"\\n\") if row.strip()]\n",
        "  table_interaction = interaction_pb2.Table()\n",
        "  table_interaction.document_title = document_title\n",
        "  table_interaction.table_id = document_title\n",
        "  if not table:\n",
        "    return table_interaction\n",
        "  for header in table[0]:\n",
        "    table_interaction.columns.add().text = header\n",
        "  for line in table[1:]:\n",
        "    row = table_interaction.rows.add()\n",
        "    for cell in line:\n",
        "      row.cells.add().text = cell\n",
        "  return table_interaction\n",
        "\n",
        "def extract_queries(queries):\n",
        "  \"\"\"Extracts the interaction for a list of queries.\n",
        "\n",
        "   This is used to create the interaction queries file.\n",
        "   Args:\n",
        "    queries: list of str queries.\"\"\"\n",
        "  for idx, query in enumerate(queries):\n",
        "    interaction = interaction_pb2.Interaction()\n",
        "    interaction.id = f\"queries_{idx}\"\n",
        "    question = interaction.questions.add()\n",
        "    question.original_text = query\n",
        "    question.id = f\"{interaction.id}-0_0\"\n",
        "    interaction.table.CopyFrom(get_table(\"FAKE\", \" | \\n | \\n\"))\n",
        "    number_annotation_utils.add_numeric_values(interaction)\n",
        "    yield interaction\n",
        "\n",
        "def write_tfrecord(filename, examples):\n",
        "  \"\"\"From interactions examples to tfrecord.\"\"\"\n",
        "  with tf.io.TFRecordWriter(filename) as writer:\n",
        "    for example in examples:\n",
        "      writer.write(example.SerializeToString())\n",
        "\n",
        "def get_config():\n",
        "  max_seq_length = 512\n",
        "  vocab_file = \"tapas_retriever/vocab.txt\"\n",
        "  config=tf_example_utils.RetrievalConversionConfig(\n",
        "      vocab_file=vocab_file,\n",
        "      max_seq_length=max_seq_length,\n",
        "      max_column_id=max_seq_length,\n",
        "      max_row_id=max_seq_length,\n",
        "      strip_column_names=False,\n",
        "      cell_trim_length=-1,\n",
        "      use_document_title=True,\n",
        "  )\n",
        "  return config\n",
        "\n",
        "def extract_queries_data(queries):\n",
        "  \"\"\"Extracts the interactions then the tf_examples.\n",
        "\n",
        "  Args:\n",
        "    queries: list of str queries.\n",
        "  \"\"\"\n",
        "  examples = extract_queries(queries)\n",
        "  input_queries = \"results/nq_retrieval/queries/queries.tfrecord\"\n",
        "  write_tfrecord(input_queries, examples)\n",
        "  config = get_config()\n",
        "  beam_runner.run_type(\n",
        "    create_data.build_retrieval_pipeline(\n",
        "        input_files=[input_queries],\n",
        "        output_files=[os.path.join(\"results/nq_retrieval/tf_examples\",\n",
        "                                   \"queries.tfrecord\")],\n",
        "        input_format=create_data.InputFormat.INTERACTION,\n",
        "        config=config,\n",
        "    ), beam_runner.RunnerType.DIRECT).wait_until_finish()\n",
        "\n",
        "# 3.   Retrieval: Extract the queries interactions to pass to the reader\n",
        "# 3.1.   Extracts the queries embeddings.\n",
        "def get_queries_embeddings():\n",
        "  ! python -m  tapas.experiments.table_retriever_experiment \\\n",
        "      --do_predict \\\n",
        "      --eval_name=\"dual_encoder_queries\" \\\n",
        "      --minutes_to_sleep_before_predictions=0 \\\n",
        "      --num_eval_steps=0 \\\n",
        "      --model_dir=\"results/nq_retrieval/model\" \\\n",
        "      --prediction_output_dir=\"results/nq_retrieval/model/queries\" \\\n",
        "      --evaluated_checkpoint_step=0 \\\n",
        "      --input_file_predict=\"results/nq_retrieval/tf_examples/queries.tfrecord\" \\\n",
        "      --bert_config_file=\"tapas_retriever/bert_config.json\" \\\n",
        "      --init_from_single_encoder=false \\\n",
        "      --tf_random_seed=\"1\" \\\n",
        "      --compression_type= \\\n",
        "      --down_projection_dim=256 \\\n",
        "      --eval_batch_size=1 \\\n",
        "      --max_seq_length=512 2> error\n",
        "\n",
        "  with open(\"results/nq_retrieval/model/queries/predict_results_0.tsv\") as csvfile_reader:\n",
        "    reader = csv.DictReader(csvfile_reader, delimiter='\\t')\n",
        "    for i, row in enumerate(reader):\n",
        "      print(\"Adding query_id: \", row[\"query_id\"], \":\", queries[i])\n",
        "\n",
        "# 3.2.   Get nearest tables neighbors for each query.\n",
        "def get_nearest_neighbors(num_neighbors):\n",
        "  queries_pred = eval_table_retriever_utils.read_queries(\"results/nq_retrieval/model/queries/predict_results_0.tsv\")\n",
        "  tables = eval_table_retriever_utils.read_tables(\"results/nq_retrieval/model/tables.tsv\", make_tables_unique=False)\n",
        "  index = eval_table_retriever_utils.build_table_index(tables)\n",
        "  similarities, neighbors = eval_table_retriever_utils._retrieve(queries_pred, index)\n",
        "  selected_tables = {}\n",
        "  for i, s in enumerate(similarities):\n",
        "    print(\"Query index\", i, \":\", queries[i])\n",
        "    selected_tables[i]={}\n",
        "    for pos in range(num_neighbors):\n",
        "      table_id = tables[neighbors[i][pos]].table_id\n",
        "      selected_tables[i][table_id] = (s[pos], neighbors[i][pos])\n",
        "      print(\"           Related table id:\", table_id)\n",
        "      print(\"           Table's score \", s[pos])\n",
        "      print(\"           ----------------------------------------------\")\n",
        "  return  selected_tables\n",
        "# 3.3.   Extract the interactions to pass to the reader.\n",
        "def iterate_tables(input_file):\n",
        "  \"\"\"Reads interaction_pb2.Table().\"\"\"\n",
        "  for value in tf.python_io.tf_record_iterator(input_file):\n",
        "    table = interaction_pb2.Table()\n",
        "    table.ParseFromString(value)\n",
        "    yield table\n",
        "\n",
        "def create_queries_tables_interactions(selected_tables):\n",
        "  \"\"\"Creates the interaction by linking the query to the selected table.\"\"\"\n",
        "  queries_interactions = prediction_utils.iterate_interactions(\n",
        "      \"results/nq_retrieval/queries/queries.tfrecord\")\n",
        "  all_tables = iterate_tables(\"tapas_models_nq_tables/tables/tables.tfrecord\")\n",
        "  tables = {table.table_id: table for table in all_tables}\n",
        "  for i, q in enumerate(queries_interactions):\n",
        "    print(\"\\n Query index:\", i, \":\", queries[i])\n",
        "    t = selected_tables[i]\n",
        "    for table_id in t.keys():\n",
        "      if table_id in tables.keys():\n",
        "        table = tables[table_id]\n",
        "        print(\"  > Converted query:\", q.questions[0].original_text)\n",
        "        new_interaction = interaction_pb2.Interaction()\n",
        "        new_interaction.CopyFrom(q)\n",
        "        new_interaction.id = f\"{new_interaction.id}_{table.table_id}\"\n",
        "        new_interaction.questions[0].id = f\"{new_interaction.id}_0\"\n",
        "        new_interaction.table.CopyFrom(table)\n",
        "        yield new_interaction\n",
        "      else:\n",
        "        print(\"  > Not found in table file.\")\n",
        "      print(\"      Related table id:  \", table_id)\n",
        "      print(\"      Table's score:     \", t[table_id][0])\n",
        "      print(\"  ----------------------------------------------\")\n",
        "\n",
        "def create_interactions_for_reader(selected_tables):\n",
        "  examples = create_queries_tables_interactions(selected_tables)\n",
        "  write_tfrecord(\"results/nq_reader/queries/reader_queries.tfrecord\", examples)\n",
        "\n",
        "# 4.   Reader: Get the answer given the question and the table\n",
        "def get_converter(max_seq_length):\n",
        "  \"\"\"Get a clssifier conferter.\"\"\"\n",
        "  config = tf_example_utils.ClassifierConversionConfig(\n",
        "      vocab_file=\"tapas_reader/vocab.txt\",\n",
        "      max_seq_length=max_seq_length,\n",
        "      max_column_id=max_seq_length,\n",
        "      max_row_id=max_seq_length,\n",
        "      strip_column_names=False,\n",
        "      add_aggregation_candidates=False,\n",
        "  )\n",
        "  return tf_example_utils.ToClassifierTensorflowExample(config)\n",
        "\n",
        "def convert_interactions_to_examples(converter):\n",
        "  \"\"\"Calls Tapas converter to convert interaction to example.\"\"\"\n",
        "  interactions = prediction_utils.iterate_interactions(\n",
        "      \"results/nq_reader/queries/reader_queries.tfrecord\")\n",
        "  for interaction in interactions:\n",
        "    try:\n",
        "      yield converter.convert(interaction, 0)\n",
        "    except ValueError as e:\n",
        "      print(f\"Can't convert interaction: {interaction.id} error: {e}\")\n",
        "\n",
        "def write_tf_example(filename, examples):\n",
        "  with tf.io.TFRecordWriter(filename) as writer:\n",
        "    for example in examples:\n",
        "      writer.write(example.SerializeToString())\n",
        "\n",
        "class Colors:\n",
        "  \"\"\"Used to highlight the answers.\"\"\"\n",
        "  ANSWER = '\\033[94m'\n",
        "  BASE = '\\033[95m'\n",
        "  BLACK = '\\033[0m'\n",
        "\n",
        "\n",
        "def set_answer_color(input, begin, end):\n",
        "  \"\"\"Highlights the answers.\"\"\"\n",
        "  list_output = [i.original_text for i in input]\n",
        "  list_output[begin] = Colors.ANSWER + list_output[begin]\n",
        "  list_output[end - 1] = list_output[end - 1] + Colors.BASE\n",
        "  return \" \".join(list_output)\n",
        "\n",
        "\n",
        "def get_table_df(table):\n",
        "  \"\"\"Extracts a dataframe table for a better visualisation.\"\"\"\n",
        "  printabe_table = [[Colors.BASE + c.text + Colors.BASE for c in table.columns]]\n",
        "  for r in table.rows:\n",
        "    printabe_table.append([Colors.BASE + c.text  + Colors.BASE for c in r.cells])\n",
        "  return pd.DataFrame(printabe_table)\n",
        "\n",
        "def predict():\n",
        "  \"\"\"Predict the answer given the query and the table.\"\"\"\n",
        "  max_seq_length = 512\n",
        "  # Extracts the tf examples given the interactions.\n",
        "  converter = get_converter(max_seq_length)\n",
        "  examples = convert_interactions_to_examples(converter)\n",
        "  write_tf_example(\"results/nq_reader/nq_retrieval/tf_examples/test.tfrecord\", examples)\n",
        "  write_tf_example(\"results/nq_reader/nq_retrieval/tf_examples/dev.tfrecord\", [])\n",
        "  # Run prediction\n",
        "  ! python -m tapas.run_task_main \\\n",
        "    --task=\"NQ_RETRIEVAL\" \\\n",
        "    --output_dir=\"results/nq_reader\" \\\n",
        "    --model_dir=\"results/nq_reader/model\" \\\n",
        "    --noloop_predict \\\n",
        "    --tapas_verbosity=\"ERROR\" \\\n",
        "    --test_batch_size={len(queries)} \\\n",
        "    --reset_position_index_per_cell \\\n",
        "    --init_checkpoint=\"tapas_reader/model.ckpt\" \\\n",
        "    --bert_config_file=\"tapas_reader/bert_config.json\" \\\n",
        "    --bert_vocab_file=\"tapas_reader/vocab.txt\" \\\n",
        "    --compression_type= \\\n",
        "    --mode=\"predict\" 2> error\n",
        "  # Display results\n",
        "  results_path = \"results/nq_reader/model/test.tsv\"\n",
        "\n",
        "  interactions = prediction_utils.iterate_interactions(\n",
        "      \"results/nq_reader/queries/reader_queries.tfrecord\")\n",
        "  tables = {\n",
        "      interaction.questions[0].id : (get_table_df(interaction.table),\n",
        "                                     interaction.table.table_id,\n",
        "                                     converter._tokenize_table(interaction.table),\n",
        "                                     interaction.questions[0].original_text)\n",
        "      for interaction in interactions}\n",
        "\n",
        "  with open(results_path) as csvfile:\n",
        "    reader = csv.DictReader(csvfile, delimiter='\\t')\n",
        "\n",
        "    for row in reader:\n",
        "      # question_id\n",
        "      df, table_id, table_tokens, query_text = tables[row[\"question_id\"]]\n",
        "      print(Colors.BLACK)\n",
        "      print(\"query >\", query_text)\n",
        "      print(\"            > table id: \", table_id)\n",
        "      print(\"            > table prediction score: \", row[\"logits_cls\"])\n",
        "      answers = ast.literal_eval(row[\"answers\"])\n",
        "      for a in answers:\n",
        "        index_r = a[\"row_index\"]\n",
        "        index_c = a[\"column_index\"]\n",
        "        colored_answer = set_answer_color(\n",
        "            table_tokens.rows[index_r+1][index_c],\n",
        "            a[\"begin_token_index\"], a[\"end_token_index\"])\n",
        "        df.iat[index_r+1, index_c] = colored_answer\n",
        "        print(\"            > Answer cell:\", Colors.BASE + colored_answer)\n",
        "        print(Colors.BLACK + \"            > Answer score:\", a[\"score\"], \"\\n\")\n",
        "      with pd.option_context(\n",
        "          'display.max_rows', None, 'display.max_columns', None,\n",
        "          'expand_frame_repr', False, 'display.unicode.ambiguous_as_wide', False,\n",
        "          'display.max_colwidth', None):\n",
        "        print(\"Table:\\n\")\n",
        "        print(Colors.BASE + df.to_string(index=False, header=False))\n",
        "      print(Colors.BLACK +\"-------------------------------------------------------------------------------------\\n\")\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOXJ_JZJFmZ6"
      },
      "source": [
        "## Run predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAyvPvoeyxAH"
      },
      "source": [
        "create_directories()\n",
        "\n",
        "new_query = \"Write your question\" #@param {type:\"string\"}\n",
        "# You can add multiple queries.\n",
        "queries = [new_query]\n",
        "\n",
        "extract_queries_data(queries)\n",
        "get_queries_embeddings()\n",
        "\n",
        "num_neighbors = 4 #@param {type:\"integer\"}\n",
        "selected_tables = get_nearest_neighbors(num_neighbors=num_neighbors)\n",
        "create_interactions_for_reader(selected_tables=selected_tables)\n",
        "\n",
        "predict()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}